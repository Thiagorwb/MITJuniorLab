{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Higgs $\\rightarrow$ ZZ $\\rightarrow$ 4L\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Standard Model and the Higgs boson\n",
    "\n",
    "The Higgs boson is an elementary particle in the Standard Model (SM), predicted by physicist Peter Higgs, whose name this particle is named after, along with five other scientists in 1964. With the collision data from the large hadron collider (LHC), the ATLAS and CMS Collaborations announced the discovery of the Higgs boson in 2012, which directly led to the Nobel Prize in the following year.\n",
    "\n",
    "The Standard Model describes the building blocks of our universe and explains how they interact. There is a series of fundamental particles: those which make matter and those carrying force.<br>\n",
    "There are basically two types of the matter particles — quarks and leptons. Each type has three generations, from the first generation — the lightest and stablest — to the second and third generations. In each generation, there are two paired-up particles, like the first generation quarks are up and down quark; and the first generation leptons electron and electron neutrino etc. All matter in the universe is made from those elementary particles, like a proton is composed of two up quarks and one down quark.<br>\n",
    "Besides, there are also force-carrier particles. It is known that there are four fundamental forces: the strong force, the weak force, the electromagnetic force, and the gravitational force. Three of them — the strong force, the weak force, the electromagnetic force — result from the exchange of force-carrier particles: the gluon for the strong force, the W and Z bosons for the weak force and the photon for the electromagnetic force, correspondingly. (There are theoretical predictions on the “graviton”, which is responsible for the gravity. Although is hasn’t been found yet.) Therefore, the big picture is, particles of matter transfer discrete amounts of energy by exchanging bosons with each other. Again the proton example, it is made from three quarks, and held together by gluons (the strong forces).\n",
    "A sketch of the SM fundamental particles are shown below. \n",
    "\n",
    "<img src=\"SM.JPG\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "The SM has successfully explained almost all experimental results and precisely predicted a wide variety of phenomena. Over time and through many experiments, it has become established as a well-tested physics theory. However, there are still a lot remaining unknown, a lot questions that the SM cannot provide an answer, like the mass of the neutrino, the dark matter and etc. Perhaps like all the transition from the classic theory to an advanced one, the SM is only a part of a bigger theory or an approximation at relative low energies which our collider can achieve. New physics awaits us in the near future.\n",
    "\n",
    "And among all those unknown, back to ten years ago, even the most important piece of the SM was still missing - the Higgs boson. As one of the fundamental particles, it is the key of the \"mechanism that contributes to our understanding of the origin of mass of subatomic particles\"[1]. Elementary particles acquire mass through their interacting with the Higgs field. And the Higgs boson is the quantum of the Higgs field, like the photon to the electromagnetic field. It was until year 2012, the Higgs boson discovery was announced by the ATLAS and CMS collaborations (on 4th July 2012). Evidence of a new particle with properties consistent with the SM-predicted Higgs boson was present in three decay modes $H \\to ZZ^* \\to 4ℓ$, $H \\to \\gamma\\gamma$, and $H \\to WW^* \\to ℓ\\nuℓ\\nu$ in both experiments.\n",
    "\n",
    "In this lab, you are going to reproduce the discovery in the so-called golden channel: $H \\to ZZ^* \\to 4ℓ$ using the LHC open data of RUN I (2009 – 2013, 7-8TeV).\n",
    "\n",
    "If interested, one can dig more with key words:\n",
    "- Standard Model\n",
    "- Higgs Boson\n",
    "\n",
    "[1] The Nobel Prize in Physics 2013"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Large Hadron Collider (LHC) and the CMS detector\n",
    "\n",
    "The Large Hadron Collider (LHC) is the world's largest and highest-energy particle collider and the largest machine in the world. It lies in a 27km circular tunnel which is ~100m deep beneath the France–Switzerland border.\n",
    "\n",
    "The LHC accelerates two beams of protons, in the opposite directions, to nearly the speed of light, and make them collide. These collisions at super high energy produce large amount of particles which allow physicists to probe the world of the infinitely small. The collisions happen at 4 points, where 4 detectors sit, the CMS detector is one of them.\n",
    "\n",
    "The CMS (Compact Muon Solenoid) detector is a cylinder 21.6 metres long and 15 metres in diameter, weighing 14,500 tons, the heaviest among the 4 detectors, almost twice heavy as the Eiffel Tower. It has a superconducting solenoid that provides an axial magnetic field of 3.8 T, and several concentric layers of components. Below is a sketch of its geometric layout.\n",
    "\n",
    "<img src=\"cms_geo.png\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "From inner to outter, in order are: <br>\n",
    "- The Silicon Tracker: Charged particles leave sign of hits in the tracker flies through interacting the silicon. Hits are joined together make a track of the traversing particle.\n",
    "\n",
    "- The Electromagnetic Calorimeter (ECAL): It is constructed from optically clear crystals of scintillating lead tungstate which stop high energy particles and produce light when hit. Thus is measures the energies of electrons and photons.\n",
    "\n",
    "- The Hadronic Calorimeter (HCAL): It is made of layers of brass and steel absorber alternating with plastic scintillators that produce light when particle traverse. Hadrons (quarks and gluons fragments as well as composite particles like pions, kaons) fly through ECAL, and are stopped in HCAL, from which the position, energy and arrival time are measured.\n",
    "\n",
    "- The Super-Conducting Solenoid Magnet: Provides the magnetic field which bends the charged particles. From the curvature of the track left in tracker, charge, monmentum and e/m ratio can be calculated, then particle identification can be made.\n",
    "\n",
    "- The Muon Detectors: Since muon is much heavier, it won't be stopped by the calorimeter. The muon detectors are built alternating with the return yoke to stop the deeply penetrating muons and measure their energies.\n",
    "\n",
    "In conclusion, different particles leave different \"footprint\" in different layers, enabling identifying (nearly) all the stable particles produced in each collision, measuring their momenta and energies, and then piecing together the information of all these particles to rebuild the whole collision and to explore new physics. A figure of the specific particle interactions in a transverse slice of the detector, from the beam interaction region to the muon detector is shown below.\n",
    "\n",
    "\n",
    "<img src=\"particle_flow.png\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "More at\n",
    "LHC: https://home.cern/science/accelerators/large-hadron-collider <br>\n",
    "CMS Detector: https://cms.cern/detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $H \\to ZZ^* \\to 4ℓ$\n",
    "\n",
    "The Higgs boson production cross section at the LHC is relatively small compared to those of other processes. The production of W and Z bosons and the production of top-quark pairs are several orders of magnitude larger than Higgs boson production, let alone tremendous QCD process. These processes lead to severe backgrounds in the Higgs boson search. In the data sample collected by the ATLAS and CMS experiments until June 2012 about 200,000 Higgs bosons with a mass of 125 GeV were expected, compared with the total number of proton-proton collisions recorded during that time $~10^{11}$. Search for the Higgs boson against such large background is like search for needles in the sea. The large backgrounds make the search almost impossible[1] in hadronic(processes with jets originated from quark-quark, quark-gluon, and gluon-gluon scattering) final states. Therefore, we can only turn to search in the non-hadronic channels where the final states contain only leptons, photons and neutrinos (missing transverse energy). One of those sensitive channels is $H \\to ZZ^* \\to 4ℓ$ (ℓ = electron or muon.[2]). The requirement of the presence of four leptons kills the hadronic background, leaving pretty clean final states. For this reason, $H \\to ZZ^* \\to 4ℓ$ is referred to as “golden channel” of the Higgs boson decays. It has the cleanest signature (non-hadronic), and also the clearest due to the complete reconstruction of the final state decay products (no neutrinos, all decay products are \"visible\") and excellent lepton momentum resolution. The Higgs boson invariant mass can be reconstructed with good precision and a sharp resonance of the Higgs boson can be searched for on top of the continuous backgrounds.\n",
    "\n",
    "\n",
    "The Feynman Diagram below shows the full chain of pp collision - Higgs boson production[3] - HtoZZto4L decay. And the figure here is a real event display in the CMS detector of $H \\to ZZ^* \\to 4ℓ$.\n",
    "<img src=\"4-lepton_Higgs_decay.svg\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "<img src=\"eventdisplay.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "\n",
    "In this decay, events are selected by firstly requiring the presence of four well reconstructed, isolated leptons ($\\mu$ or e). Here are some more explanations on \"well reconstructed\" and \"isolated\":\n",
    "\n",
    "\"The reconstructed location of the proton-proton interaction is referred to as the primary vertex — charged particle tracks reconstructed in the tracking devices converge at this point. A secondary vertex occurs when a particle originating from the interaction decays after travelling some distance from the primary vertex. The impact parameter (IP) of a reconstructed charged particle track is its distance of closest approach to the primary vertex. The magnitude of the impact parameter can be used to discriminate between the tracks of particles which originated in the interaction and those of particles produced from the decay of a relatively long-lived product of the interaction (for example a b-hadron) even if it is not possible to reconstruct a secondary vertex.\n",
    "\n",
    "Leptons and photons originating from a hard interaction, or from the decay chain of a particle, such as a Z boson or Higgs boson, directly produced in a hard interaction are not (except by chance) closely accompanied by other particles — they are isolated. Many lepton and photon candidates reconstructed in the detector do not originate directly from the hard interaction, but come from the constituents of the jets of particles formed by the hadronization of gluons or quarks. These candidates tend not to be isolated — they are surrounded by other particles from the jet. A measure of how many particles, or how much energy, surrounds a candidate lepton or photon can be used to determine whether it is probable that it emerged directly from the hard interaction, or more likely that it originated in a jet fragment.\" [*]\n",
    "\n",
    "In this Junior Lab project, this step has already been done. To reduce the size of the data and Monte Carlo (MC) simulations needed to process and to avoid complexity of points which are less important in this JLab project, the data and MC given are already pre-processed to a collection of four well-reconstructed and isolated leptons. The aim is to understand the decay of the Higgs boson to four leptons, and make use of the properties of the decay products to perform a Higgs boson search.\n",
    "\n",
    "Regardless of the relative clean and clear signature, there're still large backgrounds. The largest background comes from continuum ($Z/\\gamma^*$)($Z^*/\\gamma^*$) production, referred to as ZZ* production in the following. Below is a feynman diagram showing the leading order ZZ* production. Only the bottom right corner one is the signal (Higgs production) we want, others are all backgrounds.\n",
    "\n",
    "<img src=\"Lowest-order-Feynman-diagrams-for-ZZ-production.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "Since this background has exactly the same decay products as our signal process, it is irreducible. <br>\n",
    "Besides, there are additional backgrounds from the production of Z+jets and ttbar (top quark and antitop quark) pairs. For these backgrounds two isolated leptons emerge from $Z \\to ℓℓ$ (Z+jets) or from the decay $t \\to Wb \\to ℓ\\nu b$ (ttbar), respectively. In addition, two further leptons may originate from the decays of the fragmentation products of the heavy b-quarks or jets might be misidentified as leptons. These leptons are less isolated and, when arising from b-quarks, do not originate from the primary interaction point (where decays of the Higgs and Z bosons take place). These backgrounds are reducible. The track-isolation requirements and impact-parameter requirements in the pre-process already largely suppresses the reducible background, well below the level of the irreducible ZZ* continuum background. \n",
    "\n",
    "Then as a conclusion, you'll be performing a search for a resonance peak in the four-lepton invariant mass spectrum[4], against the large irreducible ZZ* background. The reason why such a search is difficult is that it is few signal events against thousands or sometimes even millisons backgrounds; the signal can easily be covered/erased by statistical fluctuation. To safely and scientifically interpret the data, in particle physics, an excess in data with $5\\sigma$ deviation from the background-only hypothesis is quoted as \"discovery\".  In channel $H \\to ZZ^* \\to 4ℓ$ alone, 3.2 standard deviations is reported in original publication (together with other channels more than $5\\sigma$ is reported)[5]. In this JLab project, due to the less sophisticated background suppression, it would be good to reach a ~$2\\sigma$ excess. You can compare your results with the one in publication as shown below:\n",
    "\n",
    "<img src=\"InvMass_publication.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "The key is to understand this process, the decay products properties. Then based on one's understanding, make selections to maximize the signal-to-background ratio, i.e. cut out events more background-like and at the same time keep as many signal events.\n",
    "\n",
    "Reference [*] and More on the Higgs boson discovery and its decay channels can be found:\n",
    "http://www.scholarpedia.org/article/The_Higgs_Boson_discovery#Discovery_of_the_Higgs_boson\n",
    "\n",
    "[1] Now with larger statistics and improved techniques (both hardware and software), the hadronic final states are also becoming sensitive.<br>\n",
    "[2] Z boson can also decay to $\\tau$ lepton. While $\\tau$ decays quickly, either leptonically ($\\tau \\to e/\\mu \\nu \\nu$) or hadronically. Hadronic final states are not considered, and leptonic decays are with larger missing energy due to the presence of neutrinos.<br>\n",
    "[3] There are several different ways of the Higgs boson production at a pp collider. The Feynman diagram here only shows one of them as an example. You may find more in the reference mentioned above.<br>\n",
    "[4] A search can also be performed on other variables, as long as those variables provide a good separation power between signal and background. Here the invariant mass is used because it is a powerful discriminating variable, characterising the decay topology in the rest frame of the four-lepton system.<br>\n",
    "[5] Now with higher statistics of the Run II data, in a recent publication, the signal is observed with more than 5 standard deviations in this channel alone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analysis\n",
    "\n",
    "### Open data analysis\n",
    "- This project is adapted from CERN Open Data Portal: http://opendata.cern.ch/record/5500\n",
    "\n",
    "### Data and MC\n",
    "- In the data and MC folders, you're provided collections of four well constructed and isolated leptons, with the leading lepton pT (transverse momentum) greater than 15GeV (to serve the purpose of reducing the size of provided files)\n",
    "    - File format: .csv for processing convenience with Jupyter Notebook\n",
    "    - Each entry contains 34 elements: Run,Event,PID1,Q1,E1,px1,py1,pz1,eta1,phi1,PID2,Q2,E2,px2,py2,pz2,eta2,phi2,PID3,Q3,E3,px3,py3,pz3,eta3,phi3,PID4,Q4,E4,px4,py4,pz4,eta4,phi4.\n",
    "        - They are: the Run number and event number of this event (used to label the event), the type of the lepton (you can find in this link http://pdg.lbl.gov/2007/reviews/montecarlorpp.pdf page 2 a corresponding of the PID (particle ID) and the type of the lepton, like PID = 11 means an electron.) and the kinematic information of the four leptons (their energy(E), momentum(px,py,pz), and eta and phi)\n",
    "    - Files are separated by year (2011/2012), and process (for MC)\n",
    "        - HIGHLIGHT: There are three backgrounds here: ZZ*, ttbar, and Drell-Yan. Currently only the pre-process of ZZ* are finished and the files are in the MC folder. I'm processing with ttbar and Drell-Yan, and will upload them also in the MC folder as soon as it is done.\n",
    "\n",
    "- Some concepts to understand in advance:\n",
    "    - The pseudorapidity, $\\eta$, ~eta in the file, is defined as $\\eta = -ln[tan(\\theta/2)]$, where $\\theta$ is the polar angle measured from the anticlockwise beam direction. \n",
    "    - The azimuthal angle, $\\phi$, ~phi in the file, measured the axis defined by the beam directions\n",
    "        - $\\eta - \\phi$ space gives a coordinate system\n",
    "    - The transverse momentum, pT, denotes the component of momentum perpendicular to the beam axis (in the x-y plane).\n",
    "\n",
    "### Code and work flow\n",
    "The code below provides a beginning of the analysis: open the file, read the entries, plot some distributions, and make the publication-plot you need to perform your search: the invariant mass of the four leptons. \n",
    "\n",
    "Although both the data and MC are already pre-processed, they're still far from good to claim a Higgs boson peak. Your goal here is to observe the data, play with them, make selections on the events, and reconstruct the four leptons invariant mass after the selection to try to reproduce the peak as in the publication. Remember, the dataset provided here are small because of pre-process. In reality, you may face millions or even billions number of events to dealt with!\n",
    "\n",
    "Now let's walk through the codes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as mt\n",
    "import scipy.optimize as opt\n",
    "import scipy.stats as sta\n",
    "import matplotlib.pyplot as plt\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## some scale factors and constant you might use\n",
    "\n",
    "## mass square of muon: m_muon^2 (in GeV)\n",
    "sqm1 = (0.105658) * (0.105658)\n",
    "## mass square of electron: m_e^2 (in GeV)\n",
    "sqme = (0.0005109989) * (0.0005109989)\n",
    "## mass of Z boson (in GeV)\n",
    "mZ = 91.1876\n",
    "\n",
    "\n",
    "## constants for the scale factor of MC. The MC is produced at a certain cross section\\\n",
    "## with certain number of events. To increase statistics, the event numbers generated are usually very large,\\\n",
    "## therefore a scale factor is needed to apply on the MC to make them agree with data.\n",
    "## Scale factor for each MC component is: lumi * xsec / nevt, as provided below\n",
    "\n",
    "## Luminosity of each year\n",
    "lumi12 = 11580.\n",
    "lumi11 = 2330.\n",
    "\n",
    "## MC cross section of each process\n",
    "xsecZZ412 = 0.077\n",
    "xsecZZ2mu2e12 = 0.18\n",
    "xsecZZ411 = 0.067\n",
    "xsecZZ2mu2e11 = 0.15\n",
    "\n",
    "xsecTTBar12 = 200.\n",
    "xsecTTBar11 = 177.31\n",
    "\n",
    "xsecDY5012 = 2955.\n",
    "xsecDY1012 = 10.742\n",
    "xsecDY5011 = 2475.\n",
    "xsecDY1011 = 9507.\n",
    "  \n",
    "scalexsecHZZ12 = 0.0065\n",
    "scalexsecHZZ11 = 0.0057\n",
    "\n",
    "## Number of MC Events generated for each process\n",
    "nevtZZ4mu12 = 1499064\n",
    "nevtZZ4e12 = 1499093\n",
    "nevtZZ2mu2e12 = 1497445\n",
    "nevtHZZ12 = 299973 \n",
    "nevtTTBar12 = 6423106\n",
    "nevtDY5012 = 29426492\n",
    "nevtDY1012 = 6462290\n",
    "  \n",
    "nevtZZ4mu11 = 1447136\n",
    "nevtZZ4e11 = 1493308\n",
    "nevtZZ2mu2e11 = 1479879\n",
    "nevtHZZ11 = 299683\n",
    "nevtTTBar11 = 9771205\n",
    "nevtDY5011 = 36408225\n",
    "nevtDY1011 = 39909640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'clean_data_2011.csv' does not exist: b'clean_data_2011.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-dcffd001b3dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### open the files ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# read datalist of each year and combine to one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata_year\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'clean_data_2011.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdata_year\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'clean_data_2012.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_year\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'clean_data_2011.csv' does not exist: b'clean_data_2011.csv'"
     ]
    }
   ],
   "source": [
    "### open the files ###\n",
    "# read datalist of each year and combine to one \n",
    "data_year  = [pd.read_csv('data/clean_data_2011.csv',index_col=None, header=0)]\n",
    "data_year += [pd.read_csv('data/clean_data_2012.csv',index_col=None, header=0)]\n",
    "data = pd.concat(data_year,axis=0,ignore_index=True)\n",
    "\n",
    "\n",
    "# read MClist of each process and each year, keep separate because the MC scale factor of \\\n",
    "# each year is different\n",
    "mc_higgs_11 = pd.read_csv('MC/higgs2011.csv',index_col=None, header=0)\n",
    "mc_higgs_12 = pd.read_csv('MC/higgs2012.csv',index_col=None, header=0)\n",
    "\n",
    "mc_zz4mu_11 = pd.read_csv('MC/zzto4mu2011.csv',index_col=None, header=0)\n",
    "mc_zz4mu_12 = pd.read_csv('MC/zzto4mu2012.csv',index_col=None, header=0)\n",
    "mc_zz2mu2e_11 = pd.read_csv('MC/zzto2mu2e2011.csv',index_col=None, header=0)\n",
    "mc_zz2mu2e_12 = pd.read_csv('MC/zzto2mu2e2012.csv',index_col=None, header=0)\n",
    "mc_zz4e_11 = pd.read_csv('MC/zzto4e2011.csv',index_col=None, header=0)\n",
    "mc_zz4e_12 = pd.read_csv('MC/zzto4e2012.csv',index_col=None, header=0)\n",
    "#mc_dy =\n",
    "#mc_ttbar =\n",
    "\n",
    "\n",
    "# creat a combined list to study the shape\n",
    "mc_higgs = [mc_higgs_11, mc_higgs_12]\n",
    "mc_zz = [mc_zz4mu_11, mc_zz4mu_12, mc_zz2mu2e_11, mc_zz2mu2e_12, mc_zz4e_11, mc_zz4e_12]\n",
    "#mc_bkg_dy =\n",
    "#mc_bkg_ttbar =\n",
    "\n",
    "mc_sig = pd.concat(mc_higgs,axis=0,ignore_index=True)\n",
    "mc_bkg_zz = pd.concat(mc_zz,axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the header of the csv file:\n",
    "#Run,Event,PID1,Q1,E1,px1,py1,pz1,eta1,phi1,PID2,Q2,E2,px2,py2,pz2,eta2,phi2,PID3,Q3,E3,px3,py3,pz3,eta3,phi3,PID4,Q4,E4,px4,py4,pz4,eta4,phi4\n",
    "def ReadEntries(lis):\n",
    "    return lis['PID1'],lis['Q1'],lis['E1'],lis['px1'],lis['py1'],lis['pz1'],lis['eta1'],lis['phi1'], \\\n",
    "    lis['PID2'],lis['Q2'],lis['E2'],lis['px2'],lis['py2'],lis['pz2'],lis['eta2'],lis['phi2'], \\\n",
    "    lis['PID3'],lis['Q3'],lis['E3'],lis['px3'],lis['py3'],lis['pz3'],lis['eta3'],lis['phi3'], \\\n",
    "    lis['PID4'],lis['Q4'],lis['E4'],lis['px4'],lis['py4'],lis['pz4'],lis['eta4'],lis['phi4']\n",
    "\n",
    "def pt(px, py):\n",
    "    return np.sqrt(px**2 + py**2)\n",
    "\n",
    "def invMass(E, px, py, pz):\n",
    "    return np.sqrt(E**2 - (px**2 + py**2 + pz**2))\n",
    "\n",
    "def InvMass_4l(lists):   ### faster way to get the 4l-system invMass directly from the list, as you'll use it for the final plot###\n",
    "    E_tot = lists['E1'] + lists['E2'] + lists['E3'] + lists['E4']\n",
    "    px_tot = lists['px1'] + lists['px2'] + lists['px3'] + lists['px4']\n",
    "    py_tot = lists['py1'] + lists['py2'] + lists['py3'] + lists['py4']\n",
    "    pz_tot = lists['pz1'] + lists['pz2'] + lists['pz3'] + lists['pz4']\n",
    "    return np.sqrt(E_tot**2 - (px_tot**2 + py_tot**2 + pz_tot**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get data entries\n",
    "#PID1_data, Q1_data, E1_data, px1_data, py1_data, pz1_data, eta1_data, phi1_data, \\\n",
    "#PID2_data, Q2_data, E2_data, px2_data, py2_data, pz2_data, eta2_data, phi2_data, \\\n",
    "#PID3_data, Q3_data, E3_data, px3_data, py3_data, pz3_data, eta3_data, phi3_data, \\\n",
    "#PID4_data, Q4_data, E4_data, px4_data, py4_data, pz4_data, eta4_data, phi4_data = ReadEntries(data)\n",
    "\n",
    "\n",
    "## Get MC entries\n",
    "# First sig\n",
    "#PID1_hig_11, Q1_hig_11, E1_hig_11, px1_hig_11, py1_hig_11, pz1_hig_11, eta1_hig_11, phi1_hig_11,\\\n",
    "#PID2_hig_11, Q2_hig_11, E2_hig_11, px2_hig_11, py2_hig_11, pz2_hig_11, eta2_hig_11, phi2_hig_11,\\\n",
    "#PID3_hig_11, Q3_hig_11, E3_hig_11, px3_hig_11, py3_hig_11, pz3_hig_11, eta3_hig_11, phi3_hig_11,\\\n",
    "#PID4_hig_11, Q4_hig_11, E4_hig_11, px4_hig_11, py4_hig_11, pz4_hig_11, eta4_hig_11, phi4_hig_11 = ReadEntries(mc_higgs_11)\n",
    "    \n",
    "\n",
    "# Then bkg\n",
    "#PID1_zz4mu_11, Q1_zz4mu_11, E1_zz4mu_11, px1_zz4mu_11, py1_zz4mu_11, pz1_zz4mu_11, eta1_zz4mu_11, phi1_zz4mu_11,\\\n",
    "#PID2_zz4mu_11, Q2_zz4mu_11, E2_zz4mu_11, px2_zz4mu_11, py2_zz4mu_11, pz2_zz4mu_11, eta2_zz4mu_11, phi2_zz4mu_11,\\\n",
    "#PID3_zz4mu_11, Q3_zz4mu_11, E3_zz4mu_11, px3_zz4mu_11, py3_zz4mu_11, pz3_zz4mu_11, eta3_zz4mu_11, phi3_zz4mu_11,\\\n",
    "#PID4_zz4mu_11, Q4_zz4mu_11, E4_zz4mu_11, px4_zz4mu_11, py4_zz4mu_11, pz4_zz4mu_11, eta4_zz4mu_11, phi4_zz4mu_11 = ReadEntries(mc_zz4mu_11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the main part of this analysis, to select out your signal: understand the signature of the signal (higgs) process, and make use of those signature to suppress background, but without hurting the signal yields. That is to say, find out features that signal has but background doesn't, and make a filter based on those feature, which may include:\n",
    "    - The flavor and charge of the lepton?\n",
    "    - The momentum/transverse monmentum of the lepton?\n",
    "    - It is $H \\to ZZ^* \\to 4ℓ$, how about the intermediate process, constrains on the Z boson?\n",
    "    (question: how can the Higgs boson, as a particle of 125 GeV, decay via two Z bosons, with a sum of mass greater than the mass of the Higgs?)\n",
    "    - You may want to read the original publication of the Higgs discovery: https://arxiv.org/pdf/1207.7235.pdf (notice you might find it too technical, jump over the part irrelevant to this project.) -- Hto4L part (page 10, section 5.2) to find inspiration.\n",
    "\n",
    "A way physicists usually use is to make use of MC. Since MC is generated known which process it is, then you can check distributions of the variables which you think might be different between sig and bkg with sig and bkg MC process, to see whether you want to apply a cut on this variable to help clean the data up. Let's see some examples below:\n",
    "\n",
    "Notice:\n",
    "- Here we mainly want to check the shape of the distribution, not the yields. So we no long care about the scale factor, instead we can just use the combined file of each year, each sub-process(ZZ to 4e, or 4$\\mu$, or 2e2$\\mu$), and normalize the distributions to observe the shape.\n",
    "\n",
    "- This is just an intermediate step to show the normal analysis flow, not required. You may find it useful or not, and also depends on whether it is reducible or ireducible background. You can also take whatever study you think useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## leading transverse monmentum pT\n",
    "pt1_sig = pt(mc_sig['px1'], mc_sig['py1'])\n",
    "pt1_bkg_zz = pt(mc_bkg_zz['px1'], mc_bkg_zz['py1'])\n",
    "\n",
    "hist_pt1_sig, bins_pt1_sig = np.histogram(pt1_sig, bins = 250, range = (0,250))\n",
    "hist_pt1_bkg_zz, bins_pt1_bkg_zz = np.histogram(pt1_bkg_zz, bins = 250, range = (0,250))\n",
    "bincenter_pt1 = 0.5 * (bins_pt1_sig[:-1] + bins_pt1_sig[1:])\n",
    "\n",
    "## eta of the leading lepton\n",
    "eta1_sig = mc_sig['eta1']\n",
    "eta1_bkg_zz = mc_bkg_zz['eta1']\n",
    "\n",
    "hist_eta1_sig, bins_eta1_sig = np.histogram(eta1_sig, bins = 60, range = (-3,3))\n",
    "hist_eta1_bkg_zz, bins_eta1_bkg_zz = np.histogram(eta1_bkg_zz, bins = 60, range = (-3,3))\n",
    "bincenter_eta1 = 0.5 * (bins_eta1_sig[:-1] + bins_eta1_sig[1:])\n",
    "\n",
    "\n",
    "## 4l-system invariant mass\n",
    "Etot_sig = mc_sig['E1'] + mc_sig['E2'] + mc_sig['E3'] + mc_sig['E4']\n",
    "pxtot_sig = mc_sig['px1'] + mc_sig['px2'] + mc_sig['px3'] + mc_sig['px4']\n",
    "pytot_sig = mc_sig['py1'] + mc_sig['py2'] + mc_sig['py3'] + mc_sig['py4']\n",
    "pztot_sig = mc_sig['pz1'] + mc_sig['pz2'] + mc_sig['pz3'] + mc_sig['pz4']\n",
    "invM_sig = invMass(Etot_sig, pxtot_sig, pytot_sig, pztot_sig)\n",
    "\n",
    "Etot_bkg_zz = mc_bkg_zz['E1'] + mc_bkg_zz['E2'] + mc_bkg_zz['E3'] + mc_bkg_zz['E4']\n",
    "pxtot_bkg_zz = mc_bkg_zz['px1'] + mc_bkg_zz['px2'] + mc_bkg_zz['px3'] + mc_bkg_zz['px4']\n",
    "pytot_bkg_zz = mc_bkg_zz['py1'] + mc_bkg_zz['py2'] + mc_bkg_zz['py3'] + mc_bkg_zz['py4']\n",
    "pztot_bkg_zz = mc_bkg_zz['pz1'] + mc_bkg_zz['pz2'] + mc_bkg_zz['pz3'] + mc_bkg_zz['pz4']\n",
    "invM_bkg_zz = invMass(Etot_bkg_zz, pxtot_bkg_zz, pytot_bkg_zz, pztot_bkg_zz)\n",
    "\n",
    "hist_invM_sig, bins_invM_sig = np.histogram(invM_sig, bins = 100, range = (0,500))\n",
    "hist_invM_bkg_zz, bins_invM_bkg_zz = np.histogram(invM_bkg_zz, bins = 100, range = (0,500))\n",
    "bincenter_invM = 0.5 * (bins_invM_sig[:-1] + bins_invM_sig[1:])\n",
    "\n",
    "\n",
    "plt.figure(figsize = (16,4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(bincenter_pt1, hist_pt1_sig * (1./len(pt1_sig)), color = 'b', label='$m_{H}$ = 125 GeV')\n",
    "plt.plot(bincenter_pt1, hist_pt1_bkg_zz * (1./len(pt1_bkg_zz)), color = 'r', label=r'ZZ $\\rightarrow$ 4l')\n",
    "plt.legend(fontsize = 20)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(bincenter_eta1, hist_eta1_sig * (1./len(eta1_sig)), color = 'b', label='$m_{H}$ = 125 GeV')\n",
    "plt.plot(bincenter_eta1, hist_eta1_bkg_zz * (1./len(eta1_bkg_zz)), color = 'r', label=r'ZZ $\\rightarrow$ 4l')\n",
    "plt.legend(fontsize = 20)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(bincenter_invM, hist_invM_sig * (1./len(invM_sig)), color = 'b', label='$m_{H}$ = 125 GeV')\n",
    "plt.plot(bincenter_invM, hist_invM_bkg_zz * (1./len(invM_bkg_zz)), color = 'r', label=r'ZZ $\\rightarrow$ 4l')\n",
    "plt.legend(fontsize = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, when you are satisfied with your selection, let's take a look at the data and make the invariant mass plot!\n",
    "\n",
    "Each Particle has its 4-momentum vector (E, px, py, pz) <br>\n",
    "For the four lepton individually and the 4-lepton system we have:<br>\n",
    "lepton1: p4_1 = (E1,px1,py1,pz1)<br>\n",
    "lepton2: p4_2 = (E2,px2,py2,pz2)<br>\n",
    "lepton3: p4_3 = (E3,px3,py3,pz3)<br>\n",
    "lepton3: p4_4 = (E4,px4,py4,pz4)<br>\n",
    "4-lepton: p4_4l = p4_1 + p4_2 + p4_3 + p4_4<br>\n",
    "              = (E1+E2+E3+E4, px1+px2+px3+px4, py1+py2+py3+py4, pz1+pz2+pz3+pz4)<br>\n",
    "Then the invariant mass of the 4-lepton system can be calculated:<br>\n",
    "$m_{4l} = \\sqrt{E_{4l}^2 - (px_{4l}^2 + py_{4l}^2 + pz_{4l}^2)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inM_data = InvMass_4l(data)\n",
    "\n",
    "\n",
    "### Here they need to be done separately by year and process, \n",
    "### because we want to compare the MC with data, then yields, not the shape matters here.\n",
    "### Therefore we need to apply properly the scale factor, which is different for each sub-process.\n",
    "inM_higgs_12 = InvMass_4l(mc_higgs_12)\n",
    "inM_higgs_11 = InvMass_4l(mc_higgs_11)\n",
    "\n",
    "inM_zz4mu_12 = InvMass_4l(mc_zz4mu_12)\n",
    "inM_zz4mu_11 = InvMass_4l(mc_zz4mu_11)\n",
    "inM_zz4e_12 = InvMass_4l(mc_zz4e_12)\n",
    "inM_zz4e_11 = InvMass_4l(mc_zz4e_11)\n",
    "inM_zz2mu2e_12 = InvMass_4l(mc_zz2mu2e_12)\n",
    "inM_zz2mu2e_11 = InvMass_4l(mc_zz2mu2e_11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmin = 50\n",
    "rmax = 200\n",
    "nbins = 75\n",
    "\n",
    "## data\n",
    "hist, bins = np.histogram(inM_data, bins = nbins, range = (rmin,rmax))\n",
    "binwidth = bins[1] - bins[0]\n",
    "bincenter = 0.5 * (bins[:-1] + bins[1:])\n",
    "\n",
    "\n",
    "## MC and scale each process \n",
    "## Signal\n",
    "hist_higgs_12, bins_higgs_12 = np.histogram(inM_higgs_12, bins = nbins, range = (rmin,rmax))\n",
    "hist_higgs_12 = hist_higgs_12*((lumi12 * scalexsecHZZ12) / nevtHZZ12)    ## scale, same below\n",
    "\n",
    "hist_higgs_11, bins_higgs_11 = np.histogram(inMass_higgs_11, bins = nbins, range = (rmin,rmax))\n",
    "hist_higgs_11 = hist_higgs_12*((lumi11 * scalexsecHZZ11) / nevtHZZ11)\n",
    "\n",
    "hist_higgs = hist_higgs_12 + hist_higgs_11\n",
    "\n",
    "## Background\n",
    "### ZZ*\n",
    "hist_zz4mu_12, bins_zz4mu_12 = np.histogram(inM_zz4mu_12, bins = nbins, range = (rmin,rmax))\n",
    "hist_zz4mu_12 = hist_zz4mu_12*((lumi12 * xsecZZ412) / nevtZZ4mu12)\n",
    "\n",
    "hist_zz4mu_11, bins_zz4mu_11 = np.histogram(inM_zz4mu_11, bins = nbins, range = (rmin,rmax))\n",
    "hist_zz4mu_11 = hist_zz4mu_11*((lumi11 * xsecZZ411) / nevtZZ4mu11)\n",
    "\n",
    "hist_zz4e_12, bins_zz4e_12 = np.histogram(inM_zz4e_12, bins = nbins, range = (rmin,rmax))\n",
    "hist_zz4e_12 = hist_zz4e_12*((lumi12 * xsecZZ412) / nevtZZ4e12)\n",
    "\n",
    "hist_zz4e_11, bins_zz4e_11 = np.histogram(inM_zz4e_11, bins = nbins, range = (rmin,rmax))\n",
    "hist_zz4e_11 = hist_zz4e_11*((lumi11 * xsecZZ411) / nevtZZ4e11)\n",
    "\n",
    "hist_zz2mu2e_12, bins_zz2mu2e_12 = np.histogram(inM_zz2mu2e_12, bins = nbins, range = (rmin,rmax))\n",
    "hist_zz2mu2e_12 = hist_zz2mu2e_12*((lumi12 * xsecZZ2mu2e12) / nevtZZ2mu2e12)\n",
    "\n",
    "hist_zz2mu2e_11, bins_zz2mu2e_11 = np.histogram(inM_zz2mu2e_11, bins = nbins, range = (rmin,rmax))\n",
    "hist_zz2mu2e_11 = hist_zz2mu2e_11*((lumi11 * xsecZZ2mu2e11) / nevtZZ2mu2e11)\n",
    "\n",
    "hist_zz = hist_zz4mu_12 + hist_zz4mu_11 + hist_zz4e_12 + hist_zz4e_11 + hist_zz2mu2e_12 + hist_zz2mu2e_11\n",
    "\n",
    "### DY (in pre-processing)\n",
    "### ttbar (in pre-processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now Plot it!!!\n",
    "\n",
    "plt.figure(figsize = (8,6))\n",
    "plt.style.use('mystyle.mplstyle')\n",
    "\n",
    "## Stack of BKG\n",
    "# ttbar \n",
    "\n",
    "\n",
    "# DY\n",
    "\n",
    "\n",
    "# ZZ*\n",
    "stack_zz = plt.bar(bincenter, hist_zz, align = 'center', width = binwidth, color = 'b', linewidth = 0, edgecolor = 'black',\n",
    "                 alpha = 0.5, label = r'ZZ $\\rightarrow$ 4l')\n",
    "\n",
    "\n",
    "## hist of SIG: higgs\n",
    "line_higgs = plt.bar(bincenter, hist_higgs, align = 'center', width = binwidth, color = 'w', linewidth = 1.2, edgecolor = 'r',\n",
    "                  bottom = hist_zz, label = '$m_{H}$ = 125 GeV')\n",
    "\n",
    "\n",
    "\n",
    "## Measured data\n",
    "xerrs = [binwidth*0.5 for i in range(0, nbins)]\n",
    "yerrs = np.sqrt(hist)\n",
    "marker_data = plt.errorbar(bincenter, hist, xerr = xerrs, yerr = yerrs, linestyle = 'None', color = 'black',\n",
    "                        marker = 'o', label = 'Data')\n",
    "\n",
    "\n",
    "\n",
    "plt.title('$ \\sqrt{s} = 7$ TeV, L = 2.3 $fb^{-1}$; $\\sqrt{s} = 8$ TeV, L = 11.6 $fb^{-1}$ \\n', fontsize = 15, position=(0.64,0.95))\n",
    "plt.xlabel('$m_{4l}$ [GeV]',fontsize = 20, position=(0.92,0.1))\n",
    "plt.ylabel('Events / 2 GeV',fontsize = 20, position=(0.1,0.84))\n",
    "plt.xlim(rmin,rmax)\n",
    "plt.legend(fontsize = 20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can already see the Z peak from the plot. While now mine is a direct plot from the pre-processed data, without any further selections, you can hardly distinguish the Higgs peak from the backgrounds' stat fluctuation, nor make any quantitative measurements. And also you may notice that currently the MC doesn't agree with data in current plot. That is because the MC simulations are generated already in particular model (like ZZ to 4mu, 4e or 2mu2e), while the data is a broader collection. \n",
    "\n",
    "- If your selections are reasonable, after applying those selections on both data and MC, you should see that in your plot, data agrees with MC predictions at a certain level, and also see the Higgs peak. Compare the stack of the backgrounds MC with your data, how large is your excess around 125GeV? Make use of the MC to quantify your observation.\n",
    "\n",
    "- In particle physics, and also for the actual Higgs boson discovery in 2012, what people do is so-called \"blind analysis\". A blind analysis is to optimize the selections/strategies with MC first and then apply on data once it is final, to avoids the possibility of bias of the result toward researchers' preconceptions by preventing them from knowing the answer until the analysis is complete. So of cource you can choose to do the same: to first play with MC, see how background and signal change with your selection, respectively; froze, and then apply on data once you think it's good. But here it is not required, you can always look at your data and go back to modify your modifications.\n",
    "\n",
    "- *optional: Provide a Higgs mass and width measurements based on the peak you observe.\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
